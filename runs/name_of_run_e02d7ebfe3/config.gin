from __gin__ import dynamic_registration
import cached_conv as cc
from cached_conv import convs
import rave
from rave import blocks
from rave import core
from rave import dataset
from rave import discriminator
from rave import model
from rave import pqmf
import torch

# Macros:
# ==============================================================================
CAPACITY = 64
LATENT_SIZE = 128
N_BAND = 16
PHASE_1_DURATION = 1000000
RATIOS = [4, 4, 4, 2]
SAMPLING_RATE = 44100

# Parameters for core.AudioDistanceV1:
# ==============================================================================
core.AudioDistanceV1.log_epsilon = 1e-07
core.AudioDistanceV1.multiscale_stft = @core.MultiScaleSTFT

# Parameters for model.BetaWarmupCallback:
# ==============================================================================
model.BetaWarmupCallback.initial_value = 0.1
model.BetaWarmupCallback.log = True
model.BetaWarmupCallback.target_value = 0.1
model.BetaWarmupCallback.warmup_len = 1

# Parameters for pqmf.CachedPQMF:
# ==============================================================================
pqmf.CachedPQMF.attenuation = 100
pqmf.CachedPQMF.n_band = %N_BAND

# Parameters for cc.Conv1d:
# ==============================================================================
cc.Conv1d.bias = False

# Parameters for variational/cc.Conv1d:
# ==============================================================================
variational/cc.Conv1d.bias = False

# Parameters for scales/torch.nn.Conv1d:
# ==============================================================================
scales/torch.nn.Conv1d.bias = True
scales/torch.nn.Conv1d.device = None
scales/torch.nn.Conv1d.dilation = 1
scales/torch.nn.Conv1d.dtype = None
scales/torch.nn.Conv1d.groups = 1
scales/torch.nn.Conv1d.padding = 0
scales/torch.nn.Conv1d.padding_mode = 'zeros'
scales/torch.nn.Conv1d.stride = 1

# Parameters for scales/discriminator.ConvNet:
# ==============================================================================
scales/discriminator.ConvNet.capacity = %CAPACITY
scales/discriminator.ConvNet.conv = @torch.nn.Conv1d
scales/discriminator.ConvNet.kernel_size = 15
scales/discriminator.ConvNet.n_layers = 4
scales/discriminator.ConvNet.out_size = 1
scales/discriminator.ConvNet.stride = 4

# Parameters for cc.ConvTranspose1d:
# ==============================================================================
cc.ConvTranspose1d.bias = False

# Parameters for variational/blocks.Encoder:
# ==============================================================================
variational/blocks.Encoder.capacity = %CAPACITY
variational/blocks.Encoder.data_size = %N_BAND
variational/blocks.Encoder.latent_size = %LATENT_SIZE
variational/blocks.Encoder.n_out = 2
variational/blocks.Encoder.ratios = %RATIOS
variational/blocks.Encoder.recurrent_layer = None
variational/blocks.Encoder.repeat_layers = 1
variational/blocks.Encoder.sample_norm = False
variational/blocks.Encoder.spectrogram = None

# Parameters for blocks.Generator:
# ==============================================================================
blocks.Generator.capacity = %CAPACITY
blocks.Generator.data_size = %N_BAND
blocks.Generator.latent_size = %LATENT_SIZE
blocks.Generator.loud_stride = 1
blocks.Generator.ratios = %RATIOS
blocks.Generator.recurrent_layer = None
blocks.Generator.use_noise = True

# Parameters for dataset.get_dataset:
# ==============================================================================
dataset.get_dataset.augmentations = []

# Parameters for convs.get_padding:
# ==============================================================================
convs.get_padding.dilation = 1
convs.get_padding.mode = 'centered'
convs.get_padding.stride = 1

# Parameters for scales/convs.get_padding:
# ==============================================================================
scales/convs.get_padding.dilation = 1

# Parameters for variational/convs.get_padding:
# ==============================================================================
variational/convs.get_padding.dilation = 1
variational/convs.get_padding.mode = 'centered'
variational/convs.get_padding.stride = 1

# Parameters for discriminator.MultiScaleDiscriminator:
# ==============================================================================
discriminator.MultiScaleDiscriminator.convnet = @scales/discriminator.ConvNet
discriminator.MultiScaleDiscriminator.n_discriminators = 3

# Parameters for core.MultiScaleSTFT:
# ==============================================================================
core.MultiScaleSTFT.magnitude = True
core.MultiScaleSTFT.normalized = False
core.MultiScaleSTFT.num_mels = None
core.MultiScaleSTFT.sample_rate = %SAMPLING_RATE
core.MultiScaleSTFT.scales = [2048, 1024, 512, 256, 128]

# Parameters for blocks.NoiseGenerator:
# ==============================================================================
blocks.NoiseGenerator.noise_bands = 5
blocks.NoiseGenerator.ratios = [4, 4, 4]

# Parameters for blocks.normalization:
# ==============================================================================
blocks.normalization.mode = 'weight_norm'

# Parameters for scales/blocks.normalization:
# ==============================================================================
scales/blocks.normalization.mode = 'weight_norm'

# Parameters for model.RAVE:
# ==============================================================================
model.RAVE.audio_distance = @core.AudioDistanceV1
model.RAVE.audio_monitor_epochs = 1
model.RAVE.balancer = None
model.RAVE.decoder = @blocks.Generator
model.RAVE.discriminator = @discriminator.MultiScaleDiscriminator
model.RAVE.enable_pqmf_decode = None
model.RAVE.enable_pqmf_encode = None
model.RAVE.encoder = @blocks.VariationalEncoder
model.RAVE.feature_matching_fun = @feature_matching/core.mean_difference
model.RAVE.gan_loss = @core.hinge_gan
model.RAVE.input_mode = 'pqmf'
model.RAVE.is_mel_input = None
model.RAVE.latent_size = %LATENT_SIZE
model.RAVE.loss_weights = None
model.RAVE.multiband_audio_distance = @core.AudioDistanceV1
model.RAVE.n_bands = 16
model.RAVE.num_skipped_features = 0
model.RAVE.output_mode = 'pqmf'
model.RAVE.phase_1_duration = %PHASE_1_DURATION
model.RAVE.pqmf = @pqmf.CachedPQMF
model.RAVE.sampling_rate = %SAMPLING_RATE
model.RAVE.spectrogram = None
model.RAVE.update_discriminator_every = 2
model.RAVE.valid_signal_crop = False
model.RAVE.warmup_quantize = None
model.RAVE.weights = {'feature_matching': 10}
model.RAVE.n_channels = 2

# Parameters for blocks.ResidualStack:
# ==============================================================================
blocks.ResidualStack.dilations_list = [[1, 1], [3, 1], [5, 1]]
blocks.ResidualStack.kernel_sizes = [3]

# Parameters for dataset.split_dataset:
# ==============================================================================
dataset.split_dataset.max_residual = 1000

# Parameters for blocks.VariationalEncoder:
# ==============================================================================
blocks.VariationalEncoder.beta = 1.0
blocks.VariationalEncoder.encoder = @variational/blocks.Encoder
